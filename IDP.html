<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Technical Project Sample</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Technical Project Sample</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Portfolio</a></li>
							<li><a href="information.html">Information</a></li>
							<li class="active"><a href="IDP.html">Technical Project Sample</a></li>
							<!--<li><a href="elements.html">Elements Reference</a></li>-->
						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/JasonHLAllen" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://github.com/jallen358" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">

									<h2>Beautiful Soup and Requests Python Web Scraping</h2>
									<p>This is an individual passion project that I used as an introduction to Python and many 
                                        libraries such as BeautifulSoup and Requests. The program scrapes the top 
                                        100 fantasy books from the TIME and then uses their titles to scrape their ISBNs from an 
                                        ISBN catalog.</p>
                                </header>
                                <ul>
                                    <h2>Required Libraries:</h2>
                                    <li>Numpy</li>
                                    <li>Requests</li>
                                    <li>CSV</li>
                                    <li>BS4</li>
                                </ul>
                                <p>
                                    The original goal of this project was to build up skills in Python and common data analytics 
                                    tools and strategies. By building these tools, I am now closer to starting a career in the field of Data.
                                    <h3>The steps of the code are:</h3>
                                    <ol>
                                        <li>The HTML code is scraped from the webpage by requesting the website's URL, 
                                            This code contains all of the information that I want to scrape from the page.</li>
                                        <li>This HTML code is not readable or easily traversable so I used BeautifulSoup 
                                            to allow me to traverse the HTML, searching for the information that I need to scrape. It allows 
                                            me to extract the elements by filtering based on the class or tag.</li>
                                        <li>From the TIME page, I get the Title, Author, and TIME Link to the page. I use the scraped title to build a URL to scrape the ISBN from another webpage.</li>
                                        <li>All of this information is then entered into a .csv file with headers for distinctions.
                                            The .csv file can be processed using Numpy or Pandas. At this point, I use Numpy for small amounts of computation 
                                            You can find this .csv file in the repository as well.</li>
                                        <li>These steps are repeated for all 100 books on the list.</li>
                                    </ol>
                                    There are plans for adding additional information, i.e. ratings, 
                                    which is why I scraped the IBSN but those are not complete yet.<br />
                                    In Addition to the current outputs of the code, some additional functions that I am exploring are:
                                    <ul>
                                        <li>Adding access or an abridged version of the Book Summary. 
                                            The main issue for this is that many websites do not allow scraping directly
                                            which inhibits adding this feature yet without doing more research.</li>
                                        <li>Additional Book information, i.e. Publish data, location, etc., would allow more 
                                            conclusions and comparisons to be made.
                                        </li>
                                        <li>Increasing the speed of the scraping process. At the current moment, the scraping takes 
                                            a long time because we are scraping 102 websites. Is there a way to reduce this? This task 
                                            requires more research.</li>
                                    </ul>
                                    This project started as a simple assignment but it jumpstarted my enjoyment of Data 
									Analytics as a career path. The outline of the steps is relatively simple 
									but seeing those steps take shape as I slowly widdled down the amount of HTML
									code that I received from my request was exciting. While the results of this specific
									project do not have much real-world application, it has been a great baseline for me to start from for 
									my future projects. This project has led me to many other projects, including my passion project 
									for the summer.
									The outline of those plans is listed in the GitHub repository as well.
                                    <br /> 
									<h2>Code Snippet</h2>
									<pre><code>
if __name__ == "__main__":

    url = "https://time.com/collection/100-best-fantasy-books/"

	# Getting the data from the books website
    soup = html_code(url) 
    books = soup.find_all("li", class_="section-list__item")
    
	# Variable Declarations
    holder = []
    i = 0
    j = 0
    titles = []
    isbn = []
    headers = ['Title', 'Author', 'Link', 'ISBN'] # For CSV

	# Scraping and adding to CSV Loop
    with open('books.csv', 'w') as fp:
        writer = csv.writer(fp)
        writer.writerow(headers)
        for book in books:
            link = book.find('a').get('href')
            info = book.find('h3', class_="section-list__item-headline").text.strip()

            info = info.rsplit(' by ', 1)

            title = info[0]
            if j != 0 :
                
                titleURL = "https://bookscouter.com/search?query=" + title.replace(' ', '%20').replace('\'', '')
                r = requests.get(titleURL)
                soup = BS(r.content, 'html.parser')
                isbns = soup.find_all('span', class_='BookText_b1ofiyxa')
                if len(isbns) != 0:
                    isbn = isbns[2].text
                else:
                    isbn = []
            j = j+1
            author = []
            if  len(info) == 2:
                author = info[1]

            holder = [title, author, link, isbn]

            writer.writerow(holder)
</code></pre>						
									Below you can find a PDF version of the produced .CSV File
									<object data="assets/books.pdf" type="application/pdf" width="100%" height="500px"></object>
								</p>
							</section>

					</div>

				<!-- Footer -->
					

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Jason Allen</li><li></a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>