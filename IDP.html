<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Technical Project Sample</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<a href="index.html" class="logo">Technical Project Sample</a>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li><a href="index.html">Portfolio</a></li>
							<li><a href="information.html">Information</a></li>
							<li class="active"><a href="IDP.html">Technical Project Sample</a></li>
							<!--<li><a href="elements.html">Elements Reference</a></li>-->
						</ul>
						<ul class="icons">
							<li><a href="https://twitter.com/JasonHLAllen" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
							<li><a href="https://github.com/jallen358" target="_blank" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">

									<h2>Beautiful Soup and Requests Python Web Scraping</h2>
									<p>This is an individual passion project that I used as an introduction to Python and many 
										libraries such as BeautifulSoup and Requests. The program scrapes the top 
										100 fantasy books from the TIME and then uses their titles to scrape their ISBNs from a 
										ISBN catalogue.</p>
								</header>
								<ul>
									<h2>Required Libraries:</h2>
									<li>Numpy</li>
									<li>Requests</li>
									<li>CSV</li>
									<li>BS4</li>
								</ul>
								<p>
									The original goal of this project was to build up skills in Python and common data analytics 
									tools and strategies. Building these tools, I am now closer to starting a career in the field of Data.
									<h3>The steps of the code are:</h3>
									<ol>
										<li>The html code is scraped from the webpage, 
											This code contains all of the information that I want to scrape from the page.</li>
										<li>This html code is not readible or easily traversable so I used BeautifulSoup to allow me to traverse the html, searching for the information that I need to scrape.</li>
										<li>From the TIME page I get the Title, Author, and TIME Link to the page. I use the scraped title to build a URL to scrape the ISBN from on another webpage.</li>
										<li>All of this information is then entered into a .csv file with headers for distinctions. You can find this .csv file in the repository as well.</li>
										<li>These steps are repeated for all 100 books on the list.</li>
									</ol>
									There are plans for adding additional information, i.e. ratings, which is why I scraped the IBSN but those are not complete yet.
									
									<h2>Code Snippet</h2>
									<pre><code>
if __name__ == "__main__":

    url = "https://time.com/collection/100-best-fantasy-books/"

	# Getting the data from the books website
    soup = html_code(url) 
    books = soup.find_all("li", class_="section-list__item")
    
	# Variable Declarations
    holder = []
    i = 0
    j = 0
    titles = []
    isbn = []
    headers = ['Title', 'Author', 'Link', 'ISBN'] # For CSV

	# Scraping and adding to CSV Loop
    with open('books.csv', 'w') as fp:
        writer = csv.writer(fp)
        writer.writerow(headers)
        for book in books:
            link = book.find('a').get('href')
            info = book.find('h3', class_="section-list__item-headline").text.strip()

            info = info.rsplit(' by ', 1)

            title = info[0]
            if j != 0 :
                
                titleURL = "https://bookscouter.com/search?query=" + title.replace(' ', '%20').replace('\'', '')
                r = requests.get(titleURL)
                soup = BS(r.content, 'html.parser')
                isbns = soup.find_all('span', class_='BookText_b1ofiyxa')
                if len(isbns) != 0:
                    isbn = isbns[2].text
                else:
                    isbn = []
            j = j+1
            author = []
            if  len(info) == 2:
                author = info[1]

            holder = [title, author, link, isbn]

            writer.writerow(holder)
</code></pre>						
									Below you can find a PDF version of the produced .CSV File
									<object data="assets/books.pdf" type="application/pdf" width="100%" height="500px"></object>
								</p>
							</section>

					</div>

				<!-- Footer -->
					

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; Jason Allen</li><li></a></li></ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>